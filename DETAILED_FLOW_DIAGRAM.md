# Detailed Request Flow Diagram
## Customer Message â†’ Python Backend â†’ Response

This document shows the complete flow from when a customer enters a message until they receive a response, including all Python functions called at each step.

---

## Complete Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          STEP 1: FRONTEND (React/TypeScript)                â”‚
â”‚                                                                             â”‚
â”‚  File: frontend/components/ChatContainer.tsx                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ handleSendMessage()                                                   â”‚  â”‚
â”‚  â”‚  â€¢ Creates user Message object                                        â”‚  â”‚
â”‚  â”‚  â€¢ Updates messages state                                             â”‚  â”‚
â”‚  â”‚  â€¢ Creates assistant message placeholder                              â”‚  â”‚
â”‚  â”‚  â€¢ Calls streamChat()                                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                                 â”‚
â”‚                            â–¼                                                 â”‚
â”‚  File: frontend/lib/chatApi.ts                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ streamChat({ message, sessionId, onToken, onComplete, onError })     â”‚  â”‚
â”‚  â”‚  â€¢ POST /v1/chat/stream                                              â”‚  â”‚
â”‚  â”‚  â€¢ Sets up EventSource/SSE connection                                â”‚  â”‚
â”‚  â”‚  â€¢ Reads stream chunks from response.body                            â”‚  â”‚
â”‚  â”‚  â€¢ Calls onToken() for each token received                           â”‚  â”‚
â”‚  â”‚  â€¢ Calls onComplete() when stream finishes                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ HTTP POST /v1/chat/stream
                            â”‚ { message: "Best laptop for programming", session_id: "..." }
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STEP 2: FASTAPI MIDDLEWARE LAYER                        â”‚
â”‚                                                                             â”‚
â”‚  File: backend/app/middleware/logging_middleware.py                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ LoggingMiddleware.dispatch(request, call_next)                        â”‚  â”‚
â”‚  â”‚  â€¢ Logs request start (method, path, query_params, client_ip)         â”‚  â”‚
â”‚  â”‚  â€¢ Generates request_id                                               â”‚  â”‚
â”‚  â”‚  â€¢ Calls call_next(request) â†’ proceeds to handler                    â”‚  â”‚
â”‚  â”‚  â€¢ Logs response (status_code, duration)                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                                 â”‚
â”‚                            â–¼                                                 â”‚
â”‚  File: backend/app/main.py                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ FastAPI App â†’ LoggingMiddleware â†’ CORS Middleware â†’ Routes          â”‚  â”‚
â”‚  â”‚  â€¢ Lifespan startup: init_db(), init_redis(), setup_search_provider()â”‚  â”‚
â”‚  â”‚  â€¢ Routes request to chat.router                                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STEP 3: FASTAPI API HANDLER                             â”‚
â”‚                                                                             â”‚
â”‚  File: backend/app/api/v1/chat.py                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ @router.post("/stream")                                               â”‚  â”‚
â”‚  â”‚ async def chat_stream(request: ChatRequest)                           â”‚  â”‚
â”‚  â”‚  â€¢ Validates ChatRequest (message, optional session_id)               â”‚  â”‚
â”‚  â”‚  â€¢ Generates session_id if not provided: uuid.uuid4()                 â”‚  â”‚
â”‚  â”‚  â€¢ Logs: "Chat stream started for session: {session_id}"              â”‚  â”‚
â”‚  â”‚  â€¢ Returns StreamingResponse(generate_chat_stream(...))               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                                 â”‚
â”‚                            â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ async def generate_chat_stream(message: str, session_id: str)        â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚  Step 3.1: Initialize QueryTracer                                  â”‚  â”‚
â”‚  â”‚  â€¢ Extract OpenTelemetry trace_id from HTTP span                  â”‚  â”‚
â”‚  â”‚  â€¢ Use trace_id as conversation_id for unified tracing            â”‚  â”‚
â”‚  â”‚  â€¢ Create QueryTracer(session_id, conversation_id, message)       â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  Step 3.2: Send placeholder                                       â”‚  â”‚
â”‚  â”‚  â€¢ yield "data: {token: 'Thinking...', placeholder: true}\n\n"    â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  Step 3.3: Create initial GraphState                              â”‚  â”‚
â”‚  â”‚  â€¢ GraphState(user_message=message, session_id=session_id,        â”‚  â”‚
â”‚  â”‚                metadata={"query_tracer": query_tracer}, ...)      â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  Step 3.4: Execute LangGraph workflow with tracing                â”‚  â”‚
â”‚  â”‚  â€¢ with query_tracer.trace_query(intent="unknown"):              â”‚  â”‚
â”‚  â”‚    result_state = await graph.ainvoke(initial_state)             â”‚  â”‚
â”‚  â”‚    - Updates intent in root span after detection                 â”‚  â”‚
â”‚  â”‚    - Adds metrics to HTTP span                                   â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  Step 3.5: Clear placeholder                                      â”‚  â”‚
â”‚  â”‚  â€¢ yield "data: {clear: true}\n\n"                               â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  Step 3.6: Stream response token-by-token                         â”‚  â”‚
â”‚  â”‚  â€¢ For each char in result_state.assistant_text:                 â”‚  â”‚
â”‚  â”‚    - yield "data: {token: char, done: false}\n\n"               â”‚  â”‚
â”‚  â”‚    - await asyncio.sleep(0.01)                                   â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  Step 3.7: Send final chunk with metadata                         â”‚  â”‚
â”‚  â”‚  â€¢ yield "data: {done: true, session_id, status, intent, ...}\n\n"â”‚ â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  Step 3.8: Flush Langfuse traces                                  â”‚  â”‚
â”‚  â”‚  â€¢ langfuse_client.flush() (if enabled)                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ graph.ainvoke(initial_state)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 4: LANGGRAPH WORKFLOW EXECUTION                     â”‚
â”‚                                                                             â”‚
â”‚  File: backend/app/services/langgraph/workflow.py                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ graph = build_workflow()  # Compiled StateGraph                      â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚ Workflow Structure:                                                   â”‚  â”‚
â”‚  â”‚  Entry Point: "agent_safety"                                         â”‚  â”‚
â”‚  â”‚  Nodes: agent_safety â†’ agent_intent â†’ agent_clarifier (if needed) â†’ â”‚  â”‚
â”‚  â”‚         agent_search â†’ agent_evidence (product/service) â†’            â”‚  â”‚
â”‚  â”‚         agent_normalization â†’ agent_affiliate â†’ agent_ranking â†’      â”‚  â”‚
â”‚  â”‚         agent_composer                                               â”‚  â”‚
â”‚  â”‚  Routing: route_next_agent(state) â†’ determines next node             â”‚  â”‚
â”‚  â”‚  All nodes prefixed with "agent_"                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                                 â”‚
â”‚                            â–¼                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 5: SAFETY AGENT NODE                                â”‚
â”‚                                                                             â”‚
â”‚  File: backend/app/services/langgraph/workflow.py                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ async def safety_node(state: GraphState) â†’ Dict[str, Any]           â”‚  â”‚
â”‚  â”‚  â€¢ logger.info("SAFETY AGENT - INPUT: ...")                          â”‚  â”‚
â”‚  â”‚  â€¢ result = await safety_agent_instance.execute(state)               â”‚  â”‚
â”‚  â”‚    â”‚                                                                  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚                    File: backend/app/agents/safety_agent.py      â”‚  â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ SafetyAgent.execute(state: GraphState) â†’ Dict            â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 5.1: Content Moderation                            â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ await self._moderate_content(user_text)               â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - client.moderations.create(input=text)               â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Calls OpenAI Moderation API                         â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 5.2: PII Detection & Redaction                     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ self._detect_and_redact_pii(user_text)                â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Regex patterns (email, phone, SSN, credit_card,     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                        ip_address)                        â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Returns (sanitized_text, redaction_map)             â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 5.3: Jailbreak Detection                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ self._detect_jailbreak_patterns(sanitized_text)       â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Returns: {policy_status, sanitized_text, redaction_map} â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Returns update dict:                                          â”‚  â”‚  â”‚
â”‚  â”‚    - policy_status, sanitized_text, redaction_map                â”‚  â”‚  â”‚
â”‚  â”‚    - current_agent = "safety"                                    â”‚  â”‚  â”‚
â”‚  â”‚    - next_agent = "intent" (if allowed) or None (if blocked)    â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Logger outputs: "SAFETY AGENT - OUTPUT: ..."                  â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ route_next_agent(state) â†’ "agent_intent"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 6: INTENT AGENT NODE ğŸš€ OPTIMIZED                   â”‚
â”‚                                                                             â”‚
â”‚  File: backend/app/services/langgraph/workflow.py                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ async def intent_node(state: GraphState) â†’ Dict[str, Any]           â”‚  â”‚
â”‚  â”‚  â€¢ logger.info("INTENT AGENT - INPUT: ...")                          â”‚  â”‚
â”‚  â”‚  â€¢ result = await intent_agent_instance.execute(state)               â”‚  â”‚
â”‚  â”‚    â”‚                                                                  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚                    File: backend/app/agents/intent_agent.py      â”‚  â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ IntentAgent.execute(state: GraphState) â†’ Dict            â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  ğŸš€ TWO-STEP OPTIMIZED PROCESS (15x faster)              â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     Old: Single heavy call (~30s)                         â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚     New: Two lightweight sequential calls (~2-3s total)   â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 6.1: Build Context                                  â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ self._build_context(state.conversation_history)        â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Extracts last 3 conversation turns                   â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 6.2: Quick Intent Classification (~1s)              â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ await self._quick_intent_classification(text, context) â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Uses ModelService.generate() with lightweight model  â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - response_format={"type": "json_object"}              â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Returns: intent only (intro/product/service/travel/  â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                             general)                       â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Fallback: self._fallback_classification() if error   â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 6.3: Intent-Specific Slot Extraction (~1-2s)        â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ await self._extract_slots_and_followups(               â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚        text, intent, context                              â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚      )                                                     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Uses focused prompt based on detected intent         â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Only extracts relevant slots for this intent type    â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Returns: {slots, followups}                          â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 6.4: Identify Missing Slots                         â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ self._identify_missing_slots(intent, slots)            â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Checks SLOT_DEFINITIONS[intent]["critical"]          â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 6.5: Dynamic Routing Decision (for "general")       â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ if intent == "general":                                â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚      needs_search = self._decide_general_routing(query)   â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚      - Determines if search is needed                     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚      - Routes to search if needs recent/factual data      â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚      - Routes to composer if can answer without search    â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Returns: {intent, slots, followups, missing_slots}       â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Returns update dict:                                          â”‚  â”‚  â”‚
â”‚  â”‚    - intent, slots, followups, missing_slots                     â”‚  â”‚  â”‚
â”‚  â”‚    - current_agent = "intent"                                    â”‚  â”‚  â”‚
â”‚  â”‚    - next_agent =                                                â”‚  â”‚  â”‚
â”‚  â”‚        "intro" (if intent="intro")                               â”‚  â”‚  â”‚
â”‚  â”‚        "clarifier" (if missing slots)                            â”‚  â”‚  â”‚
â”‚  â”‚        "composer" (if general + no search needed)                â”‚  â”‚  â”‚
â”‚  â”‚        "search" (otherwise)                                      â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Logger outputs: "INTENT AGENT - OUTPUT: ..."                  â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ route_next_agent(state) â†’ "agent_intro" or "agent_clarifier" or "agent_search" or "agent_composer"
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚                  â”‚
        â–¼ (intro)           â–¼ (missing slots)   â–¼ (complete)      â–¼ (general, no search)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6a: INTRO    â”‚ â”‚ STEP 7A: CLARIFIERâ”‚ â”‚ STEP 7B: SKIP  â”‚ â”‚ STEP 7C: SKIP   â”‚
â”‚      AGENT ğŸ†•     â”‚ â”‚      NODE         â”‚ â”‚ TO SEARCH      â”‚ â”‚ TO COMPOSER     â”‚
â”‚                   â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ File: workflow.py â”‚ â”‚ File: workflow.py â”‚ â”‚ (Go to Step 8) â”‚ â”‚ (Go to Step 12) â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚ async def     â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚  intro_node() â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚               â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚ File:         â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚  intro_agent  â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚  .py          â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚               â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚ IntroAgent    â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚  .execute()   â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚               â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚ â€¢ Handle      â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚   greetings   â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚   (hi, hello) â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚ â€¢ Explain     â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚   chatbot     â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚   capabilitiesâ”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚ â€¢ Generate    â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚   friendly    â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚   2-4 sent    â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚   response    â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚ â€¢ Uses GPT    â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚   with temp   â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚   =0.7        â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚               â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚ Returns:      â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚  next_agent   â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â”‚  =None (END)  â”‚ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚        â”‚          â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚        â–¼          â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â”‚       END         â”‚ â”‚                   â”‚ â”‚                â”‚ â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                       â”‚                  â”‚
                            â”‚ (if not halted)       â”‚                  â”‚
                            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 7A (continued):         â”‚
â”‚  CLARIFIER NODE               â”‚
â”‚                               â”‚
â”‚  File: workflow.py            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚                               â”‚
â”‚  â”‚ async def               â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚   clarifier_node()      â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â€¢ logger.info("CLARIFIERâ”‚ â”‚  â”‚                               â”‚
â”‚  â”‚    AGENT - INPUT: ...")  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â€¢ result = await       â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚    clarifier_agent_     â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚    instance.execute()   â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚    â”‚                    â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  File: clarifier_    â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚        agent.py      â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚ ClarifierAgent  â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚ .execute()      â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚                 â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚ â€¢ Check if      â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   resume:       â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   await self.   â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   _check_if_    â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   resume()      â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   - redis.existsâ”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚                 â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚ â€¢ If new:       â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   await self.   â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   _handle_new_  â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   clarification â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   - Saves halt  â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     state to    â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     Redis:      â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     await self. â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     _save_halt_ â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     state()     â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   - Returns     â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     halt_       â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     required=Trueâ”‚â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚                 â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚ â€¢ If resume:    â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   await self.   â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   _handle_      â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   resume()      â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   - await self. â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     _get_halt_  â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     state()     â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   - Updates     â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     slots       â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   - await self. â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     _clear_halt â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     _state()    â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚   - Returns     â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     halt_       â”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â”‚     required=Falseâ”‚ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚                      â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚ â€¢ Returns update:    â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚   - If halt:         â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚     status="halted"  â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚     halt_reason=...  â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚     followups=[...]  â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚     next_agent=None  â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚   - If resume:       â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚     status="running" â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚     next_agent=      â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â”‚     "search"         â”‚  â”‚  â”‚  â”‚                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚                               â”‚
â”‚                               â”‚  â”‚  â”‚                               â”‚
â”‚  (If halted, workflow ENDS)   â”‚  â”‚  â”‚                               â”‚
â”‚  (User must respond first)    â”‚  â”‚  â”‚                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ (if not halted, or after resume)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 8: SEARCH AGENT NODE                                â”‚
â”‚                                                                             â”‚
â”‚  File: backend/app/services/langgraph/workflow.py                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ async def search_node(state: GraphState) â†’ Dict[str, Any]           â”‚  â”‚
â”‚  â”‚  â€¢ logger.info("SEARCH AGENT - INPUT: ...")                          â”‚  â”‚
â”‚  â”‚  â€¢ result = await search_agent_instance.execute(state)               â”‚  â”‚
â”‚  â”‚    â”‚                                                                  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚                    File: backend/app/agents/search_agent.py      â”‚  â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ SearchAgent.execute(state: GraphState) â†’ Dict            â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 8.1: Generate Search Query                         â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ self._generate_search_query(state)                    â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Uses intent and slots to build query                â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Returns optimized search query string               â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 8.2: Check Redis Cache                             â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ await self._get_cached_results(search_query)          â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - cache_key = f"search:{md5_hash}"                    â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - await redis.get(cache_key)                          â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Returns cached results if found                     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 8.3: Call Search Manager (if not cached)           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ await self.search_manager.search(                     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚        query=search_query,                               â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚        intent=state.intent,                              â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚        max_results=10                                    â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚      )                                                    â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Uses configured search provider (SearchProvider)    â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Provider loaded from config/search.yaml or env      â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Default: Perplexity                                 â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Returns SearchResult objects                        â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Converts to dict format for state                   â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 8.4: Process Results                               â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ self._deduplicate_results(results)                    â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Removes duplicate URLs                              â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ self._rank_by_authority(deduplicated)                 â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Scores domains (wirecutter=10, etc.)                â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Sorts by authority_score                            â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Step 8.5: Cache Results                                 â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ await self._cache_results(query, ranked)              â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - await redis.setex(cache_key, TTL, json.dumps(...))  â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Returns: {search_results, search_query, cached}         â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Returns update dict:                                          â”‚  â”‚  â”‚
â”‚  â”‚    - search_results, search_query                                â”‚  â”‚  â”‚
â”‚  â”‚    - current_agent = "search"                                    â”‚  â”‚  â”‚
â”‚  â”‚    - next_agent = "evidence" (if product/service) or             â”‚  â”‚  â”‚
â”‚  â”‚                   "composer" (if travel/general)                 â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Logger outputs: "SEARCH AGENT - OUTPUT: ..."                  â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ route_next_agent(state) â†’ "agent_evidence" (product/service) or "agent_composer" (travel/general)
                            â”‚
                            â”‚ (If product/service intent)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 8.5: EVIDENCE AGENT NODE                            â”‚
â”‚                                                                             â”‚
â”‚  File: backend/app/services/langgraph/workflow.py                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ async def evidence_node(state: GraphState) â†’ Dict[str, Any]         â”‚  â”‚
â”‚  â”‚  â€¢ logger.info("EVIDENCE AGENT - INPUT: ...")                        â”‚  â”‚
â”‚  â”‚  â€¢ result = await evidence_agent_instance.execute(state)             â”‚  â”‚
â”‚  â”‚    â”‚                                                                  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚                    File: backend/app/agents/evidence_agent.py    â”‚  â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ EvidenceAgent.execute(state: GraphState) â†’ Dict          â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ Extract review aspects from search results            â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ Analyze pros/cons                                     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ Track evidence citations                               â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ Calculate confidence score                             â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Returns: {review_aspects, evidence_citations,           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚            confidence_score}                              â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Returns update dict:                                          â”‚  â”‚  â”‚
â”‚  â”‚    - review_aspects, evidence_citations, confidence_score        â”‚  â”‚  â”‚
â”‚  â”‚    - current_agent = "evidence"                                  â”‚  â”‚  â”‚
â”‚  â”‚    - next_agent = "composer"                                     â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Logger outputs: "EVIDENCE AGENT - OUTPUT: ..."                â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ route_next_agent(state) â†’ "agent_composer"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 9: NORMALIZATION AGENT NODE                         â”‚
â”‚                                                                             â”‚
â”‚  File: backend/app/services/langgraph/workflow.py                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ async def normalization_node(state: GraphState) â†’ Dict[str, Any]    â”‚  â”‚
â”‚  â”‚  â€¢ logger.info("NORMALIZATION AGENT - INPUT: ...")                   â”‚  â”‚
â”‚  â”‚  â€¢ result = await normalization_agent_instance.execute(state)       â”‚  â”‚
â”‚  â”‚    â”‚                                                                  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚                    File: backend/app/agents/normalization_agent.pyâ”‚  â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ NormalizationAgent.execute(state: GraphState) â†’ Dict     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ Canonicalize entity (brand/model/category/attrs)      â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ Generate entity_key                                   â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Returns: {entity, entity_key}                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Returns update dict:                                          â”‚  â”‚  â”‚
â”‚  â”‚    - entity, entity_key                                          â”‚  â”‚  â”‚
â”‚  â”‚    - current_agent = "normalization"                             â”‚  â”‚  â”‚
â”‚  â”‚    - next_agent = "affiliate"                                    â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ route_next_agent(state) â†’ "agent_affiliate"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 10: AFFILIATE AGENT NODE                            â”‚
â”‚                                                                             â”‚
â”‚  File: backend/app/services/langgraph/workflow.py                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ async def affiliate_node(state: GraphState) â†’ Dict[str, Any]        â”‚  â”‚
â”‚  â”‚  â€¢ logger.info("AFFILIATE AGENT - INPUT: ...")                       â”‚  â”‚
â”‚  â”‚  â€¢ result = await affiliate_agent_instance.execute(state)            â”‚  â”‚
â”‚  â”‚    â”‚                                                                  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚                    File: backend/app/agents/affiliate_agent.py   â”‚  â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ AffiliateAgent.execute(state: GraphState) â†’ Dict         â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ Resolve and validate affiliate links                  â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Returns: {affiliate_links, link_health}                 â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Returns update dict:                                          â”‚  â”‚  â”‚
â”‚  â”‚    - affiliate_links, link_health                                â”‚  â”‚  â”‚
â”‚  â”‚    - current_agent = "affiliate"                                  â”‚  â”‚  â”‚
â”‚  â”‚    - next_agent = "ranking"                                       â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ route_next_agent(state) â†’ "agent_ranking"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 11: RANKING AGENT NODE                              â”‚
â”‚                                                                             â”‚
â”‚  File: backend/app/services/langgraph/workflow.py                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ async def ranking_node(state: GraphState) â†’ Dict[str, Any]          â”‚  â”‚
â”‚  â”‚  â€¢ logger.info("RANKING AGENT - INPUT: ...")                          â”‚  â”‚
â”‚  â”‚  â€¢ result = await ranking_agent_instance.execute(state)              â”‚  â”‚
â”‚  â”‚    â”‚                                                                  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚                    File: backend/app/agents/ranking_agent.py     â”‚  â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ RankingAgent.execute(state: GraphState) â†’ Dict           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ Rank/diversify items                                 â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Returns: {ranked_items}                                 â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Returns update dict:                                          â”‚  â”‚  â”‚
â”‚  â”‚    - ranked_items                                                â”‚  â”‚  â”‚
â”‚  â”‚    - current_agent = "ranking"                                   â”‚  â”‚  â”‚
â”‚  â”‚    - next_agent = "composer"                                     â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ route_next_agent(state) â†’ "agent_composer"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 12: COMPOSER AGENT NODE                              â”‚
â”‚                                                                             â”‚
â”‚  File: backend/app/services/langgraph/workflow.py                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ async def composer_node(state: GraphState) â†’ Dict[str, Any]         â”‚  â”‚
â”‚  â”‚  â€¢ logger.info("COMPOSER AGENT - INPUT: ...")                        â”‚  â”‚
â”‚  â”‚  â€¢ result = await composer_agent_instance.execute(state)             â”‚  â”‚
â”‚  â”‚    â”‚                                                                  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚                    File: backend/app/agents/composer_agent.py    â”‚  â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚ ComposerAgent.execute(state: GraphState) â†’ Dict          â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Routes based on intent:                                 â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  If intent == "product" or "service":                    â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ await self._compose_product_response(state)           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - self._build_search_context(search_results)          â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - await model_service.generate(...)                   â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚      â€¢ Uses ModelService with GPT-4o                     â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚      â€¢ Token counting and cost tracking                  â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - self._extract_citations(search_results)             â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Creates ui_blocks (carousel, pros_cons)             â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  If intent == "travel":                                  â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ await self._compose_travel_response(state)            â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Similar flow with travel-specific prompts          â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Creates ui_blocks (hotel_cards, flight_cards,      â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                         itinerary)                       â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  If intent == "comparison":                              â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ await self._compose_comparison_response(state)        â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚    - Creates comparison_table ui_block                   â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  If intent == "general":                                 â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  â€¢ await self._compose_general_response(state)           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚                                                           â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â”‚  Returns: {assistant_text, ui_blocks, citations}         â”‚  â”‚  â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Returns update dict:                                          â”‚  â”‚  â”‚
â”‚  â”‚    - assistant_text, ui_blocks, citations                        â”‚  â”‚  â”‚
â”‚  â”‚    - current_agent = "composer"                                  â”‚  â”‚  â”‚
â”‚  â”‚    - status = "completed"                                        â”‚  â”‚  â”‚
â”‚  â”‚    - next_agent = None (END)                                     â”‚  â”‚  â”‚
â”‚  â”‚  â€¢ Logger outputs: "COMPOSER AGENT - OUTPUT: ..."                â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ route_next_agent(state) â†’ END (workflow complete)
                            â”‚
                            â”‚ (Workflow complete, return result_state)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 13: STREAMING RESPONSE BACK (GENERIC) ğŸš€           â”‚
â”‚                                                                             â”‚
â”‚  File: backend/app/api/v1/chat.py                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Back in generate_chat_stream()                                       â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚  ğŸš€ GENERIC STREAMING ARCHITECTURE                                   â”‚  â”‚
â”‚  â”‚  â€¢ No hardcoded logic for specific data types                        â”‚  â”‚
â”‚  â”‚  â€¢ Agents declare what to stream via stream_chunk_data               â”‚  â”‚
â”‚  â”‚  â€¢ API layer blindly forwards whatever exists                        â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚  Step 13.1: Check for stream_chunk_data in result                    â”‚  â”‚
â”‚  â”‚  â€¢ stream_data = output_data.get("stream_chunk_data")                â”‚  â”‚
â”‚  â”‚  â€¢ if stream_data:                                                   â”‚  â”‚
â”‚  â”‚      - Clear placeholder: yield "data: {clear: true}\n\n"           â”‚  â”‚
â”‚  â”‚      - Extract type and data from stream_data                        â”‚  â”‚
â”‚  â”‚      - Build chunk with data_type as key:                            â”‚  â”‚
â”‚  â”‚        chunk = {data_type: data_content, done: False}                â”‚  â”‚
â”‚  â”‚      - Check for create_new_message flag:                            â”‚  â”‚
â”‚  â”‚        if stream_data.get("create_new_message"):                     â”‚  â”‚
â”‚  â”‚          chunk["create_new_message"] = True                          â”‚  â”‚
â”‚  â”‚      - yield "data: {json.dumps(chunk)}\n\n"                        â”‚  â”‚
â”‚  â”‚      - Mark data_already_streamed = True                             â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚  Step 13.2: Check for halt status                                    â”‚  â”‚
â”‚  â”‚  â€¢ if output_data.get("halt"):                                       â”‚  â”‚
â”‚  â”‚      - Send halt chunk with followups:                               â”‚  â”‚
â”‚  â”‚        yield "data: {halt: true, followups: [...], done: true}\n\n" â”‚  â”‚
â”‚  â”‚      - return (workflow halted, waiting for user)                    â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚  Step 13.3: Stream final response (if not halted)                    â”‚  â”‚
â”‚  â”‚  â€¢ if data_already_streamed:                                         â”‚  â”‚
â”‚  â”‚      - Send status update: "ğŸ“‹ Preparing your travel plan..."       â”‚  â”‚
â”‚  â”‚  â€¢ Clear placeholder: yield "data: {clear: true}\n\n"              â”‚  â”‚
â”‚  â”‚  â€¢ Stream response token-by-token:                                   â”‚  â”‚
â”‚  â”‚    response_text = result_state.assistant_text                       â”‚  â”‚
â”‚  â”‚    for char in response_text:                                        â”‚  â”‚
â”‚  â”‚      yield "data: {token: char, done: false}\n\n"                   â”‚  â”‚
â”‚  â”‚      await asyncio.sleep(0.01)                                       â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚  Step 13.4: Send final chunk with metadata                           â”‚  â”‚
â”‚  â”‚  â€¢ yield "data: {done: true, session_id, status, intent,            â”‚  â”‚
â”‚  â”‚                   ui_blocks, citations, followups}\n\n"              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ SSE Stream (text/event-stream)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 14: FRONTEND RECEIVES STREAM                        â”‚
â”‚                                                                             â”‚
â”‚  File: frontend/lib/chatApi.ts                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ In streamChat() function:                                            â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚  â€¢ reader = response.body.getReader()                                â”‚  â”‚
â”‚  â”‚  â€¢ while (true):                                                     â”‚  â”‚
â”‚  â”‚      const {done, value} = await reader.read()                       â”‚  â”‚
â”‚  â”‚      buffer += decoder.decode(value)                                 â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚      For each line starting with "data: ":                           â”‚  â”‚
â”‚  â”‚        const chunk = JSON.parse(line.slice(6))                       â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚        if (chunk.clear):                                             â”‚  â”‚
â”‚  â”‚          onClear()  â†’ Clears placeholder                             â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚        if (chunk.token):                                             â”‚  â”‚
â”‚  â”‚          onToken(chunk.token)  â†’ Updates UI                          â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚        if (chunk.done):                                              â”‚  â”‚
â”‚  â”‚          onComplete({session_id, status, intent, ...})               â”‚  â”‚
â”‚  â”‚          return                                                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                                 â”‚
â”‚                            â–¼                                                 â”‚
â”‚  File: frontend/components/ChatContainer.tsx                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ onToken(token) callback:                                             â”‚  â”‚
â”‚  â”‚  â€¢ Updates messages state                                            â”‚  â”‚
â”‚  â”‚  â€¢ Appends token to assistant message content                        â”‚  â”‚
â”‚  â”‚  â€¢ React re-renders â†’ User sees streaming text                       â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚ onComplete(data) callback:                                           â”‚  â”‚
â”‚  â”‚  â€¢ Sets session_id if provided                                       â”‚  â”‚
â”‚  â”‚  â€¢ Sets isStreaming = false                                          â”‚  â”‚
â”‚  â”‚  â€¢ Logs completion                                                   â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚ onError(errorMsg) callback:                                          â”‚  â”‚
â”‚  â”‚  â€¢ Sets error state                                                  â”‚  â”‚
â”‚  â”‚  â€¢ Updates last message with error text                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    USER SEES RESPONSE IN UI
```

---

## Function Call Summary

### Frontend Functions (TypeScript)
1. `ChatContainer.handleSendMessage()` - Creates message and initiates stream
2. `chatApi.streamChat()` - Sets up SSE connection and handles stream
3. `ChatContainer.onToken()` - Updates UI for each token
4. `ChatContainer.onComplete()` - Handles stream completion

### Backend Python Functions

#### Middleware
1. `LoggingMiddleware.dispatch()` - Logs request/response

#### API Layer
2. `chat.chat_stream()` - FastAPI endpoint handler
3. `chat.generate_chat_stream()` - SSE stream generator

#### LangGraph Workflow
4. `workflow.build_workflow()` - Creates StateGraph (called once at startup)
5. `workflow.route_next_agent()` - Determines next node based on state.next_agent
6. `workflow.safety_node()` - Safety agent wrapper
7. `workflow.intent_node()` - Intent agent wrapper
8. `workflow.clarifier_node()` - Clarifier agent wrapper
9. `workflow.search_node()` - Search agent wrapper
10. `workflow.evidence_node()` - Evidence agent wrapper
11. `workflow.normalization_node()` - Normalization agent wrapper
12. `workflow.affiliate_node()` - Affiliate agent wrapper
13. `workflow.ranking_node()` - Ranking agent wrapper
14. `workflow.composer_node()` - Composer agent wrapper

#### Safety Agent
12. `workflow.safety_node()` - Safety agent wrapper
13. `SafetyAgent.execute()` - Main safety logic
14. `SafetyAgent._moderate_content()` - OpenAI Moderation API call
15. `SafetyAgent._detect_and_redact_pii()` - PII detection with regex
16. `SafetyAgent._detect_jailbreak_patterns()` - Jailbreak detection

#### Intent Agent (Optimized)
17. `workflow.intent_node()` - Intent agent wrapper
18. `IntentAgent.execute()` - Main intent logic (two-step optimized)
19. `IntentAgent._build_context()` - Builds conversation context
20. `IntentAgent._quick_intent_classification()` - Step 1: Quick intent classification (~1s)
21. `IntentAgent._extract_slots_and_followups()` - Step 2: Intent-specific slot extraction (~1-2s)
22. `IntentAgent._fallback_classification()` - Keyword-based fallback
23. `IntentAgent._identify_missing_slots()` - Checks for missing critical slots
24. `IntentAgent._decide_general_routing()` - Determines if general query needs search

#### Intro Agent (New)
25. `workflow.intro_node()` - Intro agent wrapper
26. `IntroAgent.execute()` - Main intro logic
27. `IntroAgent._generate_intro_response()` - Generates friendly greeting/capability response

#### Clarifier Agent (if needed)
28. `workflow.clarifier_node()` - Clarifier agent wrapper
29. `ClarifierAgent.execute()` - Main clarifier logic
30. `ClarifierAgent._check_if_resume()` - Checks Redis for halted state
31. `ClarifierAgent._handle_new_clarification()` - Handles new clarification
32. `ClarifierAgent._handle_resume()` - Handles resume from halt
33. `ClarifierAgent._save_halt_state()` - Saves state to Redis
34. `ClarifierAgent._get_halt_state()` - Retrieves state from Redis
35. `ClarifierAgent._clear_halt_state()` - Clears Redis halt state
36. `ClarifierAgent._update_slots_with_answer()` - Updates slots with user answer

#### Search Agent
37. `workflow.search_node()` - Search agent wrapper
38. `SearchAgent.execute()` - Main search logic
39. `SearchAgent._generate_search_query()` - Builds search query from intent/slots
40. `SearchAgent._get_cached_results()` - Checks Redis cache
41. `SearchManager.search()` - Calls configured search provider (via search manager)
42. `SearchProvider.search()` - Abstract provider interface (OpenAI default, Perplexity available)
43. `SearchAgent._extract_product_names()` - NEW: Extracts product names using LLM from search results
44. `SearchAgent._deduplicate_results()` - Removes duplicate URLs
45. `SearchAgent._rank_by_authority()` - Ranks by domain authority
46. `SearchAgent._extract_domain()` - Extracts domain from URL
47. `SearchAgent._cache_results()` - Caches results in Redis
48. `SearchAgent._get_cache_key()` - Generates MD5 cache key

#### Parallel Product Processing Node (NEW - product intent only)
49. `workflow.parallel_product_node()` - Runs Evidence + Affiliate in parallel
50. `asyncio.gather()` - Parallel execution of both agents

#### Evidence Agent (product/service intents) ğŸš€ PARALLEL
51. `workflow.parallel_product_node()` - Wrapper (runs in parallel)
52. `EvidenceAgent.execute()` - Main evidence logic
53. `EvidenceAgent._extract_product_evidence()` - NEW: Parallel processing for all products
54. `EvidenceAgent._extract_single_product_evidence()` - NEW: Extract evidence for one product
55. `asyncio.gather()` - Parallel execution for multiple products

#### Affiliate Agent ğŸš€ PARALLEL
56. `workflow.parallel_product_node()` - Wrapper (runs in parallel)
57. `AffiliateAgent.execute()` - Main affiliate logic
58. `AffiliateAgent._search_by_product_names()` - NEW: Search for all products in parallel
59. `AffiliateAgent._search_single_product_affiliate()` - NEW: Search one product on eBay
60. `asyncio.gather()` - Parallel execution for multiple products

#### Normalization Agent (REFACTORED)
61. `workflow.normalization_node()` - Normalization agent wrapper
62. `NormalizationAgent.execute()` - Main normalization logic
63. `NormalizationAgent._merge_evidence_and_ranking()` - NEW: Merges evidence + affiliate + ranking data
64. (DEPRECATED) `NormalizationAgent._extract_entities()` - Old entity extraction (still present, unused)

#### Ranking Agent
65. `workflow.ranking_node()` - Ranking agent wrapper
66. `RankingAgent.execute()` - Rank/diversify items

#### Composer Agent (ENHANCED)
67. `workflow.composer_node()` - Composer agent wrapper
68. `ComposerAgent.execute()` - Main composer logic (routes by intent)
69. `ComposerAgent._compose_product_response()` - Product/service response with normalized_products
70. `ComposerAgent._compose_travel_response()` - Travel response
71. `ComposerAgent._compose_comparison_response()` - Comparison response
72. `ComposerAgent._compose_general_response()` - General Q&A response
73. `ModelService.generate()` - GPT-4o API call (via ModelService)
74. `ComposerAgent._build_search_context()` - Builds context from search results
75. `ComposerAgent._extract_citations()` - Extracts citation URLs
76. `ComposerAgent._create_carousel_block()` - NEW: Creates carousel UI with first affiliate link
77. `ComposerAgent._create_product_review_blocks()` - NEW: Creates product review UI with all affiliate links

#### Tracing & Observability
78. `QueryTracer.trace_query()` - End-to-end query tracing
79. `QueryTracer.trace_agent()` - Individual agent tracing
80. `QueryTracer.record_llm_call()` - Records LLM metrics
81. `QueryTracer.record_cache_hit()` - Records cache hits
82. `ModelService.generate()` - Token counting and cost tracking (LiteLLM)

---

## External API Calls

1. **OpenAI Moderation API** - Called by `SafetyAgent._moderate_content()`
2. **OpenAI GPT-4o-mini API** - Called via `ModelService.generate()` in `IntentAgent`
3. **OpenAI GPT-4o API** - Called via `ModelService.generate()` in `ComposerAgent` and `EvidenceAgent`
4. **Search Provider API** (configurable) - Called by `SearchManager.search()` â†’ `SearchProvider.search()`
   - Current Default: OpenAI Web Search API (configurable via `config/search.yaml`)
   - Alternative: Perplexity API
   - Can be swapped to other providers (Tavily, Bing, etc.) without code changes
   - Provider loaded dynamically based on config (only needed provider is imported)
   - OpenAI provider uses intent-specific optimizations (product, service, travel)
5. **eBay Browse API** - Called by `AffiliateAgent` via `eBayProvider`
   - Product search by name
   - Parallel searches for multiple products
   - Top 3 affiliate links per product
6. **Redis** - Multiple calls for caching and state management:
   - Cache search results (get/set)
   - Halt state persistence (get/set/delete)
7. **Langfuse API** (optional) - Called for tracing and observability:
   - Via OpenTelemetry OTLP export (if enabled)
   - Via Langfuse SDK for generation tracking

---

## Data Structures

### GraphState (Blackboard Pattern)
- Shared state passed through all agents
- Each agent reads/writes to this state
- Defined in `backend/app/schemas/graph_state.py`

### Key State Fields:
- `user_message` - Original user input
- `sanitized_text` - After PII redaction
- `intent` - Classified intent (product/travel/general/intro)
- `slots` - Extracted slot values
- `search_results` - Results from search provider (OpenAI/Perplexity)
- `product_names` - NEW: Extracted product names for parallel processing
- `review_aspects` - Product reviews with features, pros, cons
- `affiliate_links` - Affiliate links from eBay
- `ranked_items` - Ranked products
- `normalized_products` - NEW: Merged evidence + affiliate + ranking data
- `travel_info` - Enriched travel information (destination, dates, budget, etc.)
- `itinerary` - Day-by-day travel itinerary
- `hotels` - Hotel search results
- `flights` - Flight search results
- `stream_chunk_data` - **NEW**: Data to stream immediately `{"type": "...", "data": [...], "create_new_message": bool}`
- `assistant_text` - Final response text
- `ui_blocks` - UI components (carousel, product_review, pros_cons, etc.)
- `citations` - Citation URLs
- `status` - running/halted/completed/error
- `halt` - Whether workflow should halt for user input
- `halt_reason` - Reason for halting
- `next_agent` - Determines workflow routing

---

## Travel Flow - Detailed Multi-Stage Sequence

### Travel Intent Flow (Step-by-Step)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRAVEL FLOW: Stage 1 - Slot Collection & Itinerary                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User: "I want to travel to Tokyo"
    â†“
Intent Agent â†’ Detects intent="travel"
    â†“
Travel Clarifier Agent (First Call)
    â†“
    â€¢ Checks halt state: is_resume = await HaltStateManager.check_if_resume(session_id)
    â€¢ is_resume = False (no halt state exists)
    â€¢ Extract slots from user message:
        - destination: "Tokyo" âœ…
        - check_in: None âŒ
        - check_out: None âŒ
        - travelers: None âŒ
        - budget: None âŒ
    â€¢ Identify missing critical slots: [check_in, check_out, travelers]
    â€¢ Check if showed_itinerary: False
    â†“
    [Missing slots + No itinerary shown yet]
    â†“
Travel Itinerary Agent
    â†“
    â€¢ Generate day-by-day itinerary for Tokyo
    â€¢ Create stream_chunk_data:
        {
            "type": "itinerary",
            "data": [...],
            "create_new_message": True  # Create new message for itinerary
        }
    â€¢ Mark showed_itinerary = True in halt state:
        await HaltStateManager.update_field(session_id, "showed_itinerary", True)
    â€¢ Return: next_agent = "travel_clarifier"
    â†“
[Workflow passes stream_chunk_data to chat.py]
    â†“
chat.py (generate_chat_stream):
    â†“
    â€¢ Detect stream_chunk_data in result
    â€¢ Clear placeholder
    â€¢ Stream itinerary data: yield "data: {itinerary: [...], create_new_message: true}\n\n"
    â€¢ Mark data_already_streamed = True
    â†“
[Frontend displays itinerary in new message]
    â†“
Travel Clarifier Agent (Second Call - after itinerary)
    â†“
    â€¢ Slots still incomplete
    â€¢ showed_itinerary = True (from halt state)
    â€¢ Generate follow-up questions:
        "I've prepared an itinerary for Tokyo! To help you book hotels and flights:
        - When would you like to check in?
        - When would you like to check out?
        - How many travelers?"
    â€¢ Save halt state to Redis:
        await HaltStateManager.update_halt_state(session_id, {
            "intent": "travel",
            "slots": {"destination": "Tokyo"},
            "followups": [...],
            "halt_reason": "Missing travel dates and travelers",
            "showed_itinerary": True,
            "travel_info": {...}
        })
    â€¢ Return: halt=True, next_agent=None
    â†“
chat.py:
    â†“
    â€¢ Detect halt=True
    â€¢ Send halt chunk: yield "data: {halt: true, followups: [...], done: true}\n\n"
    â†“
[Frontend displays follow-up questions]
[Workflow HALTED - waiting for user response]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRAVEL FLOW: Stage 2 - Resume & Booking                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User: "Check in Dec 1, check out Dec 5, 2 travelers"
    â†“
Safety Agent â†’ Pass
    â†“
Intent Agent â†’ Detects intent="travel" (matches halted intent)
    â†“
Travel Clarifier Agent (Resume Call)
    â†“
    â€¢ Check halt state: is_resume = await HaltStateManager.check_if_resume(session_id, "travel")
    â€¢ is_resume = True (halt state exists, intent matches)
    â€¢ Load halt state from Redis:
        halt_state = await HaltStateManager.get_halt_state(session_id)
        {
            "intent": "travel",
            "slots": {"destination": "Tokyo"},
            "showed_itinerary": True,
            "travel_info": {...}
        }
    â€¢ Restore state from halt_state
    â€¢ Update slots with user answer:
        - check_in: Dec 1 âœ…
        - check_out: Dec 5 âœ…
        - travelers: 2 âœ…
    â€¢ Validate all critical slots: All complete! âœ…
    â€¢ Delete halt state: await HaltStateManager.delete_halt_state(session_id)
    â€¢ Return: halt=False, next_agent="travel_planner"
    â†“
Travel Planner Agent
    â†“
    â€¢ Load existing itinerary from state (generated earlier):
        itinerary = state.get("itinerary", [])
    â€¢ Search hotels for Tokyo (Dec 1-5, 2 travelers)
    â€¢ Search flights for Tokyo (Dec 1-5, 2 travelers)
    â€¢ Build travel_results:
        {
            "destination": "Tokyo",
            "hotels": [...],
            "flights": [...],
            "itinerary": [...],  # Reuse existing itinerary
            "budget": {...}
        }
    â€¢ Return: next_agent="composer"
    â†“
Composer Agent
    â†“
    â€¢ Compose final travel response with hotels + flights
    â€¢ Create UI blocks: hotel_cards, flight_cards
    â€¢ Note: Itinerary NOT included in UI blocks (already shown earlier)
    â€¢ Return: assistant_text, ui_blocks, status="completed"
    â†“
chat.py:
    â†“
    â€¢ Stream final response with hotel/flight cards
    â€¢ yield "data: {done: true, ui_blocks: [...], ...}\n\n"
    â†“
[Frontend displays hotels and flights]
[Workflow COMPLETED]
```

---

## HaltStateManager - Two-Tier Caching Architecture

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PROCESS-LEVEL CACHE                             â”‚
â”‚  Python Dict: {session_id: halt_state_data}                        â”‚
â”‚  â€¢ Shared across all method calls in same request/process          â”‚
â”‚  â€¢ Fast access (no network calls)                                  â”‚
â”‚  â€¢ Automatically cleared between requests                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†• (load on cache miss)
                            â†• (save on every update)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     REDIS PERSISTENT STORAGE                        â”‚
â”‚  Key: "halt_state:{session_id}"                                    â”‚
â”‚  TTL: 1 hour (3600 seconds)                                        â”‚
â”‚  â€¢ Persists across requests                                        â”‚
â”‚  â€¢ Survives server restarts (with TTL)                             â”‚
â”‚  â€¢ Enables HALT/RESUME pattern                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Methods Flow

**get_halt_state(session_id, force_reload=False)**
```
1. Check if session_id in process cache
   â”œâ”€ Yes â†’ Return cached data (no Redis call)
   â””â”€ No â†’ Load from Redis
       â”œâ”€ exists = await redis.exists(f"halt_state:{session_id}")
       â”œâ”€ if not exists â†’ Cache None, return None
       â””â”€ if exists:
           â”œâ”€ halt_state_json = await redis.get(key)
           â”œâ”€ halt_state_data = json.loads(halt_state_json)
           â”œâ”€ Cache it: _cache[session_id] = halt_state_data
           â””â”€ Return halt_state_data
```

**update_halt_state(session_id, result_state)**
```
1. Build halt_state_data with core fields:
   {
       "intent": result_state.get("intent"),
       "slots": result_state.get("slots", {}),
       "followups": result_state.get("followups", []),
       "halt_reason": result_state.get("halt_reason")
   }

2. Dynamically preserve ALL other fields:
   for key, value in result_state.items():
       if key not in halt_state_data and not key.startswith("_"):
           halt_state_data[key] = value
   # This preserves: showed_itinerary, travel_info, etc.

3. Update process cache FIRST:
   _cache[session_id] = halt_state_data

4. Persist to Redis:
   json_data = json.dumps(halt_state_data, cls=DateTimeEncoder)
   await redis.setex(f"halt_state:{session_id}", 3600, json_data)
```

**update_field(session_id, field_name, field_value)**
```
1. Load current halt state:
   halt_state = await get_halt_state(session_id)

2. Update the field:
   halt_state[field_name] = field_value
   # Creates new field if doesn't exist

3. Save back to Redis and cache:
   await update_halt_state(session_id, halt_state)
```

**check_if_resume(session_id, current_intent)**
```
1. Load halt state:
   halt_state = await get_halt_state(session_id)

2. If no halt state â†’ return False

3. Check intent match:
   if current_intent != halt_state.get("intent"):
       â”œâ”€ Delete halt state (intent changed)
       â””â”€ return False

4. return True (valid resume)
```

**delete_halt_state(session_id)**
```
1. Remove from process cache:
   if session_id in _cache:
       del _cache[session_id]

2. Remove from Redis:
   await redis.delete(f"halt_state:{session_id}")
```

### Usage Example in Travel Clarifier

```python
# Check if resuming
is_resume = await HaltStateManager.check_if_resume(session_id, "travel")

if is_resume:
    # Load halt state (from cache or Redis)
    halt_state = await HaltStateManager.get_halt_state(session_id)

    # Restore slots, showed_itinerary, travel_info, etc.
    slots = halt_state.get("slots", {})
    showed_itinerary = halt_state.get("showed_itinerary", False)

    # Update slots with new user answer
    # ...

    # Delete halt state (workflow resuming)
    await HaltStateManager.delete_halt_state(session_id)
else:
    # New clarification - save halt state
    await HaltStateManager.update_halt_state(session_id, {
        "intent": "travel",
        "slots": slots,
        "followups": followups,
        "halt_reason": "Missing travel dates",
        "showed_itinerary": True,  # Dynamically preserved
        "travel_info": travel_info  # Dynamically preserved
    })
```

---

## Error Handling

- Each agent has try/except blocks
- Errors are added to `state.errors`
- If critical error: `state.status = "error"`, workflow ends
- Errors are logged via Python logging module
- Frontend receives error chunks via SSE

---

## Performance Optimizations

1. **Parallel Product Processing** ğŸš€ - Evidence + Affiliate agents run in parallel â†’ ~70% speed improvement
2. **LLM-based Product Extraction** - Extract product names from search results for accurate matching
3. **Redis Caching** - Search results cached for 24 hours (MD5 key-based)
4. **SSE Streaming** - Response streamed token-by-token for perceived speed
5. **Conditional Routing** - Only necessary agents execute (based on intent)
6. **HALT/RESUME** - Avoids re-processing when waiting for user input (Redis state persistence)
7. **Modular Search Providers** - Search providers loaded dynamically based on config (only needed provider is imported)
8. **Provider Abstraction** - Easy to switch search providers without code changes (OpenAI/Perplexity)
9. **Intent-Specific Search** - OpenAI provider uses domain filters per intent type (product/service/travel)
10. **QueryTracer** - Unified tracing with OpenTelemetry + Langfuse for cost/token tracking
11. **ModelService** - Centralized LLM calls with LiteLLM for token counting and cost tracking
12. **Database Connection Pooling** - Increased pool size to 50 for parallel agent workflows
13. **Generic Streaming Architecture** ğŸš€ NEW - Agents declare streaming behavior, API layer just forwards (no type checks)
14. **HaltStateManager Two-Tier Caching** ğŸš€ NEW - Process-level cache + Redis minimizes network calls
15. **Dynamic Field Preservation** ğŸš€ NEW - No hardcoded field names in halt state, automatically preserves all fields
16. **Travel Multi-Stage Flow** ğŸš€ NEW - Show itinerary FIRST before booking, better UX and prevents duplicate displays
17. **Node Wrapper Pass-Through** ğŸš€ NEW - Workflow nodes explicitly pass through streaming fields

---

## File Locations Reference

- Frontend: `frontend/components/ChatContainer.tsx`, `frontend/lib/chatApi.ts`
- API: `backend/app/api/v1/chat.py` - Generic SSE streaming endpoint
- Middleware: `backend/app/middleware/logging_middleware.py`
- Workflow: `backend/app/services/langgraph/workflow.py` - LangGraph StateGraph with node wrappers
- Agents: `backend/app/agents/*.py`
  - `backend/app/agents/safety_agent.py` - Content moderation & PII detection
  - `backend/app/agents/intent_agent.py` - Intent classification & slot extraction
  - `backend/app/agents/search_agent.py` - Web search orchestration
  - `backend/app/agents/clarifier_agent.py` - General clarification & HALT/RESUME
  - `backend/app/agents/travel_clarifier_agent.py` - ğŸš€ NEW: Travel-specific slot validation
  - `backend/app/agents/travel_itinerary_agent.py` - ğŸš€ NEW: Itinerary generation with streaming
  - `backend/app/agents/travel_planner_agent.py` - Hotel/flight booking
  - `backend/app/agents/evidence_agent.py` - Review extraction & pros/cons
  - `backend/app/agents/normalization_agent.py` - Product entity normalization
  - `backend/app/agents/affiliate_agent.py` - Affiliate link resolution
  - `backend/app/agents/ranking_agent.py` - Product ranking & diversification
  - `backend/app/agents/composer_agent.py` - Final response composition
- State Schema: `backend/app/schemas/graph_state.py` - GraphState with stream_chunk_data field
- State Management: ğŸš€ NEW
  - `backend/app/services/halt_state_manager.py` - Two-tier caching (Process + Redis) with dynamic fields
  - `backend/app/services/slot_accessor.py` - Centralized slot access utilities
- Search Services: `backend/app/services/search/*.py`
  - `backend/app/services/search/manager.py` - SearchManager
  - `backend/app/services/search/base.py` - SearchProvider interface
  - `backend/app/services/search/config.py` - Provider configuration
  - `backend/app/services/search/registry.py` - Provider registry
  - `backend/app/services/search/providers/` - Provider implementations
    - `openai_provider.py` - OpenAI web search (current default)
    - `perplexity_provider.py` - Perplexity search (alternative)
- Model Service: `backend/app/services/model_service.py` - LiteLLM integration
- Observability:
  - `backend/app/core/observability.py` - OpenTelemetry + Langfuse setup
  - `backend/app/core/custom_tracing.py` - QueryTracer for end-to-end tracking
- Main App: `backend/app/main.py`
- Config:
  - `backend/config/search.yaml` - Search provider configuration
  - `backend/app/core/config.py` - Application settings
- Frontend Components:
  - `frontend/components/ChatContainer.tsx` - Main chat interface with streaming
  - `frontend/components/ProductCarousel.tsx` - Product carousel UI
  - `frontend/components/ProductReview.tsx` - Product review cards UI
  - `frontend/lib/chatApi.ts` - Chat API client with SSE support

